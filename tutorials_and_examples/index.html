<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Tutorials and Examples Â· GradValley.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">GradValley.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../(pre-trained)_models/">(Pre-Trained) Models</a></li><li><a class="tocitem" href="../getting_started/">Getting Started</a></li><li><a class="tocitem" href="../installation/">Installation</a></li><li class="is-active"><a class="tocitem" href>Tutorials and Examples</a><ul class="internal"><li><a class="tocitem" href="#A-LeNet-like-model-for-handwritten-digit-recognition"><span>A LeNet-like model for handwritten digit recognition</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Tutorials and Examples</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Tutorials and Examples</a></li></ul></nav><div class="docs-right"><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Tutorials-and-Examples"><a class="docs-heading-anchor" href="#Tutorials-and-Examples">Tutorials and Examples</a><a id="Tutorials-and-Examples-1"></a><a class="docs-heading-anchor-permalink" href="#Tutorials-and-Examples" title="Permalink"></a></h1><p>Here you can find detailed explanations on how to build and train specific models with GradValley.jl.</p><h2 id="A-LeNet-like-model-for-handwritten-digit-recognition"><a class="docs-heading-anchor" href="#A-LeNet-like-model-for-handwritten-digit-recognition">A LeNet-like model for handwritten digit recognition</a><a id="A-LeNet-like-model-for-handwritten-digit-recognition-1"></a><a class="docs-heading-anchor-permalink" href="#A-LeNet-like-model-for-handwritten-digit-recognition" title="Permalink"></a></h2><p>In this tutorial, we will learn the basics of GradValley.jl while building a model for handwritten digit recognition reaching approximately 99% accuracy on the MNIST-dataset. The whole code at once can be found <a href=".">here</a>.</p><h3 id="Importing-modules"><a class="docs-heading-anchor" href="#Importing-modules">Importing modules</a><a id="Importing-modules-1"></a><a class="docs-heading-anchor-permalink" href="#Importing-modules" title="Permalink"></a></h3><pre><code class="language-julia hljs">using GradValley # The master module of GradValley.jl
using GradValley.Layers # The &quot;Layers&quot; module provides all the building blocks for creating a model. 
using GradValley.Optimization # The &quot;Optimization&quot; module provides different loss functions and optimizers.</code></pre><h3 id="Using-the-dataset"><a class="docs-heading-anchor" href="#Using-the-dataset">Using the dataset</a><a id="Using-the-dataset-1"></a><a class="docs-heading-anchor-permalink" href="#Using-the-dataset" title="Permalink"></a></h3><p>We will using the MLDatasets package which downloads the MNIST-dataset for us automatically. If you haven&#39;t installed MLDatasets yet, write this for <a href="https://juliaml.github.io/MLDatasets.jl/stable/#Installation">installation</a>:</p><pre><code class="language-julia hljs">import Pkg; Pkg.add(&quot;MLDatasets&quot;)</code></pre><p>Then we can import MLDatasets:</p><pre><code class="language-julia hljs">using MLDatasets # A package for downloading datasets</code></pre><h4 id="Splitting-up-the-dataset-in-a-train-and-a-test-partition"><a class="docs-heading-anchor" href="#Splitting-up-the-dataset-in-a-train-and-a-test-partition">Splitting up the dataset in a train- and a test-partition</a><a id="Splitting-up-the-dataset-in-a-train-and-a-test-partition-1"></a><a class="docs-heading-anchor-permalink" href="#Splitting-up-the-dataset-in-a-train-and-a-test-partition" title="Permalink"></a></h4><p>The MNIST-dataset contains 70,000 images, we will use 60,000 images for training the network and 10,000 images for evaluating accuracy.</p><pre><code class="language-julia hljs"># Initialize train- and test-dataset
mnist_train = MNIST(:train) 
mnist_test = MNIST(:test)</code></pre><h4 id="Using-GradValley.DataLoader-for-handling-data"><a class="docs-heading-anchor" href="#Using-GradValley.DataLoader-for-handling-data">Using GradValley.DataLoader for handling data</a><a id="Using-GradValley.DataLoader-for-handling-data-1"></a><a class="docs-heading-anchor-permalink" href="#Using-GradValley.DataLoader-for-handling-data" title="Permalink"></a></h4><p>A typical workflow when dealing with datasets is to use the GradValley.DataLoader struct. A data loader makes it easy to iterate directly over the batches in a dataset.  Due to better memory efficiency, the data loader loads the batches <em>just in time</em>. When initializing a data loader, we specify a function that returns exactly one element from the dataset at a given index. We also have to specify the size of the dataset (e.g. the number of images). All parameters that the dataloader accepts (see <a href=".">Reference</a> for more information):</p><pre><code class="language-julia hljs">DataLoader(get_function::Function, dataset_size::Integer; batch_size::Integer=1, shuffle::Bool=false, drop_last::Bool=false)</code></pre><p>Now we write the <em>get function</em> for the two data loaders.</p><pre><code class="language-julia hljs"># function for getting an image and the corressponding target vector from the train or test partition
function get_element(index, partition)
    # load one image and the corresponding label
    if partition == &quot;train&quot;
        image, label = mnist_train[index]
    else # test partition
        image, label = mnist_test[index]
    end
    # add channel dimension
    image = reshape(image, 1, 28, 28)
    # generate the target vector from the label, one for the correct digit, zeros for the wrong digits
    targets = zeros(10)
    targets[label + 1] = 1.00

    return image, label
end</code></pre><p>We can now initialitze the data loaders.</p><pre><code class="language-julia hljs">train_data_loader = DataLoader(index -&gt; get_element(index, &quot;train&quot;), length(mnist_train), batch_size=32)
test_data_loader = DataLoader(index -&gt; get_element(index, &quot;test&quot;), length(mnist_test), batch_size=32)</code></pre><p>If you want to force the data loader to load the data all at once, you could do:</p><pre><code class="language-julia hljs"># depending on the dataset&#39;s size, this may take a while
train_data = train_data_loader[begin:end]
test_data = test_data_loader[begin:end]</code></pre><h3 id="Building-the-neuronal-network-aka.-the-model"><a class="docs-heading-anchor" href="#Building-the-neuronal-network-aka.-the-model">Building the neuronal network aka. the model</a><a id="Building-the-neuronal-network-aka.-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Building-the-neuronal-network-aka.-the-model" title="Permalink"></a></h3><p>The most recommend way to build models is to use the GradValley.Layers.SequentialContainer struct. A SequtialContainer can take an array of layers or other SequentialContainers (sub-models). While forward-pass, the given inputs are <em>sequentially</em> propagated through every layer (or sub-model) and the output will be returned. For more details, see <a href=".">Reference</a>. The LeNet5 model is one of the earliest convolutional neuronal networks (CNNs) reaching approximately 99% accuracy on the MNIST-dataset. The LeNet5 is build from two main parts, the feature extractor and the classifier. So it would be a good idea to clarify that in the code:</p><pre><code class="language-julia hljs"># Definition of a LeNet-like model consisting of a feature extractor and a classifier
feature_extractor = SequentialContainer([ # a convolution layer with 1 in channel, 6 out channels, a 5*5 kernel and a relu activation
                                         Conv(1, 6, (5, 5), activation_function=&quot;relu&quot;),
                                         # a average pooling layer with a 2*2 filter (when not specified, stride is automatcally set to kernel size)
                                         AvgPool((2, 2)),
                                         Conv(6, 16, (5, 5), activation_function=&quot;relu&quot;),
                                         AvgPool((2, 2))])
flatten = Reshape((256, ))
classifier = SequentialContainer([ # a fully connected layer (also known as dense or linear) with 256 in features, 120 out features and a relu activation
                                  Fc(256, 120, activation_function=&quot;relu&quot;),
                                  Fc(120, 84, activation_function=&quot;relu&quot;),
                                  Fc(84, 10),
                                  # a softmax activation layer, the softmax will be calculated along the second dimension (the features dimension)
                                  Softmax(dim=2)])
# The final model consists of three different sub-modules, 
# which shows that a SequentialContainer can contain not only layers, but also other SequentialContainers
model = SequentialContainer([feature_extractor, flatten, classifier])</code></pre><h4 id="Defining-hyperparameters"><a class="docs-heading-anchor" href="#Defining-hyperparameters">Defining hyperparameters</a><a id="Defining-hyperparameters-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-hyperparameters" title="Permalink"></a></h4><p>Before we start to train and test the model, we define all necessary hyperparamters. If we want to change the learning rate or the loss function for example, this is the one place to do this.</p><pre><code class="language-julia hljs"># defining hyperparameters
loss_function = mse_loss # mean squared error
learning_rate = 0.05
optimizer = MSGD(model, learning_rate, momentum=0.5) # momentum stochastic gradient decent with a momentum of 0.5
epochs = 20</code></pre><h3 id="Train-the-model"><a class="docs-heading-anchor" href="#Train-the-model">Train the model</a><a id="Train-the-model-1"></a><a class="docs-heading-anchor-permalink" href="#Train-the-model" title="Permalink"></a></h3></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../installation/">Â« Installation</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.23 on <span class="colophon-date" title="Sunday 8 January 2023 21:31">Sunday 8 January 2023</span>. Using Julia version 1.7.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
